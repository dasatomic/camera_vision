{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\aleks\\.conda\\envs\\env_pytorch\\lib\\site-packages\\tqdm\\auto.py:22: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "%matplotlib inline\n",
    "from matplotlib import pyplot as plt\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "torch.set_printoptions(edgeitems=2)\n",
    "torch.manual_seed(123)\n",
    "from PIL import Image\n",
    "from torchvision import transforms\n",
    "to_tensor = transforms.ToTensor()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This first part is about data capturing.\n",
    "Capture 100s of images with hand up and hand down and put them in folder."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from pathlib import Path\n",
    "landing_folder = \"./camera_landing_zone/\"\n",
    "\n",
    "Path(landing_folder).mkdir(parents=True, exist_ok=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "import os\n",
    "from PIL import Image\n",
    "import uuid\n",
    "\n",
    "cv2.namedWindow(\"preview\")\n",
    "vc = cv2.VideoCapture(0)\n",
    "\n",
    "if vc.isOpened(): # try to get the first frame\n",
    "    rval, frame = vc.read()\n",
    "else:\n",
    "    rval = False\n",
    "\n",
    "while rval:\n",
    "    PIL_image = Image.fromarray(np.uint8(frame)).convert('RGB')\n",
    "    image_name = f\"./camera_landing_zone/%s.jpg\" % uuid.uuid4().hex\n",
    "    PIL_image.save(image_name)\n",
    "    cv2.imshow(\"preview\", frame)\n",
    "    rval, frame = vc.read()\n",
    "\n",
    "    key = cv2.waitKey(20)\n",
    "    if key == 27: # exit on ESC\n",
    "        break\n",
    "\n",
    "vc.release()\n",
    "cv2.destroyWindow(\"preview\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_mean_and_std():\n",
    "    folder_hand_down = \"./camera_landing_zone/hand_down/\"\n",
    "    folder_hand_up = \"./camera_landing_zone/hand_up/\"\n",
    "    to_tensor = transforms.ToTensor()\n",
    "\n",
    "    lst_images = []\n",
    "\n",
    "    for folder_name in [folder_hand_down, folder_hand_up]:\n",
    "        for file_name in os.listdir(folder_name):\n",
    "            img_t = Image.open(folder_name + file_name)\n",
    "            lst_images.append(to_tensor(img_t))\n",
    "\n",
    "    tensor_all_images = torch.stack(lst_images, dim=3)\n",
    "    # I have C X H X W X N.\n",
    "    print(tensor_all_images.shape)\n",
    "\n",
    "    return tensor_all_images.view(3,-1).mean(dim=1), tensor_all_images.view(3,-1).std(dim=1)\n",
    "\n",
    "find_mean_and_std()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# trying to use my custom loader.\n",
    "from hand_up_down_loader import HandUpDownDataSet\n",
    "import random\n",
    "from typing import Tuple\n",
    "\n",
    "def create_loaders(test_ratio = 0.2) -> Tuple[HandUpDownDataSet, HandUpDownDataSet]:\n",
    "    folder_hand_down = \"./camera_landing_zone/hand_down/\"\n",
    "    folder_hand_up = \"./camera_landing_zone/hand_up/\"\n",
    "\n",
    "    file_paths_down = [folder_hand_down + file_name for file_name in os.listdir(folder_hand_down)]\n",
    "    file_paths_up = [folder_hand_up + file_name for file_name in os.listdir(folder_hand_up)]\n",
    "\n",
    "    results = np.array(([0] * len(file_paths_down)) + ([1] * len(file_paths_up)))\n",
    "    file_paths = np.array(file_paths_down + file_paths_up)\n",
    "\n",
    "    # permute data for test and training\n",
    "    # seems like I don't even need to do shuffling.\n",
    "    # but let's keep it for now.\n",
    "    permutation = [x for x in range(0, len(file_paths))]\n",
    "    random.shuffle(permutation)\n",
    "\n",
    "    train_size = int((1-test_ratio) * len(permutation))\n",
    "\n",
    "    train_indices = permutation[:train_size]\n",
    "    test_indices = permutation[train_size:]\n",
    "\n",
    "    train_file_paths = file_paths[train_indices].tolist()\n",
    "    train_results = results[train_indices].tolist()\n",
    "\n",
    "    test_file_paths = file_paths[test_indices].tolist()\n",
    "    test_results = results[test_indices].tolist()\n",
    "\n",
    "    loader_train = HandUpDownDataSet(\n",
    "        file_list=train_file_paths,\n",
    "        root=\"./camera_landing_zone/\",\n",
    "        targets=train_results,\n",
    "        transform=transforms.Compose(transforms=[\n",
    "            transforms.ToTensor(),\n",
    "            transforms.Normalize((0.4918, 0.4837, 0.5035),\n",
    "                                 (0.2523, 0.2437, 0.2239))\n",
    "        ])\n",
    "    )\n",
    "\n",
    "    loader_test = HandUpDownDataSet(\n",
    "        file_list=test_file_paths,\n",
    "        root=\"./camera_landing_zone/\",\n",
    "        targets=test_results,\n",
    "        transform=transforms.Compose(transforms=[\n",
    "            transforms.ToTensor(),\n",
    "            transforms.Normalize((0.4918, 0.4837, 0.5035),\n",
    "                                 (0.2523, 0.2437, 0.2239))\n",
    "        ])\n",
    "    )\n",
    "    return loader_train, loader_test\n",
    "\n",
    "loader_train, loader_test = create_loaders()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0, Loss 0.482407\n",
      "Accuracy_test: 0.762825\n",
      "Epoch 10, Loss 0.101468\n",
      "Accuracy_test: 0.985874\n",
      "Epoch 20, Loss 0.062577\n",
      "Accuracy_test: 0.994052\n"
     ]
    }
   ],
   "source": [
    "import torch.nn as nn\n",
    "\n",
    "model = nn.Sequential(\n",
    "    nn.Linear(480 * 640 * 3, 512, device='cuda'),\n",
    "    nn.Tanh(),\n",
    "    nn.Linear(512, 256, device='cuda'),\n",
    "    nn.Tanh(),\n",
    "    nn.Linear(256, 300, device='cuda'),\n",
    "    nn.Tanh(),\n",
    "    nn.Linear(300, 2, device='cuda'),\n",
    "    nn.LogSoftmax(dim=1)\n",
    ")\n",
    "\n",
    "learning_rate = 1e-3\n",
    "optimizer = torch.optim.SGD(model.parameters(), lr=learning_rate)\n",
    "loss_fn = nn.NLLLoss()\n",
    "n_epoch = 25\n",
    "\n",
    "train_loader =torch.utils.data.DataLoader(loader_train, batch_size=512, shuffle=False)\n",
    "test_loader = torch.utils.data.DataLoader(loader_test, batch_size=256, shuffle=False)\n",
    "\n",
    "for epoch in range(n_epoch):\n",
    "    for imgs, labels in train_loader:\n",
    "        input_train_tensor_cuda = imgs.cuda()\n",
    "        result_train_tensor_cuda = labels.cuda()\n",
    "        train_outs = model(input_train_tensor_cuda.view(-1, 480 * 640 * 3))\n",
    "        loss = loss_fn(train_outs, result_train_tensor_cuda.long())\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "    if epoch % 10 == 0:\n",
    "        print(\"Epoch %d, Loss %f\" % (epoch, float(loss)))\n",
    "        with torch.no_grad():\n",
    "            total = 0\n",
    "            correct = 0\n",
    "            for imgs, labels in test_loader:\n",
    "                test_outs = model(imgs.cuda().view(-1, 480 * 640 * 3))\n",
    "                _, predicted = torch.max(test_outs, dim=1)\n",
    "                total += imgs.shape[0]\n",
    "                correct += int((predicted == labels.cuda().long()).sum())\n",
    "\n",
    "            print(\"Accuracy_test: %f\" % (correct / total))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(model, \"models/model_hand_pavle.pickle\")\n",
    "# ok, so this model 1.7 GB. Which is huge."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_new = torch.load(\"models/model_hand_pavle.pickle\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# so accuracy is 100% let's see if this is for real.\n",
    "import cv2\n",
    "import numpy as np\n",
    "import os\n",
    "from PIL import Image\n",
    "\n",
    "cv2.namedWindow(\"preview\")\n",
    "vc = cv2.VideoCapture(0)\n",
    "\n",
    "if vc.isOpened(): # try to get the first frame\n",
    "    rval, frame = vc.read()\n",
    "else:\n",
    "    rval = False\n",
    "\n",
    "file_id = 0\n",
    "\n",
    "normalizer = transforms.Normalize((0.4918, 0.4837, 0.5035),\n",
    "                                 (0.2523, 0.2437, 0.2239))\n",
    "\n",
    "while rval:\n",
    "    PIL_image = Image.fromarray(np.uint8(frame)).convert('RGB')\n",
    "    image_tensor = normalizer(to_tensor(PIL_image)).cuda()\n",
    "    model_out = model_new(image_tensor.view(-1).unsqueeze(0))\n",
    "    prob, predicted = torch.max(model_out, dim=1)\n",
    "\n",
    "    font = cv2.FONT_HERSHEY_SIMPLEX\n",
    "    org = (50, 50)\n",
    "    fontScale = 1\n",
    "    color = (255, 0, 0)\n",
    "    thickness = 2\n",
    "    txt = \"state: %d, prob: %f\" % (int(predicted), float(prob))\n",
    "    frame = cv2.putText(frame, txt, org, font, fontScale, color, thickness, cv2.LINE_AA)\n",
    "    cv2.imshow(\"preview\", frame)\n",
    "\n",
    "    rval, frame = vc.read()\n",
    "\n",
    "\n",
    "    key = cv2.waitKey(20)\n",
    "    if key == 27: # exit on ESC\n",
    "        break\n",
    "\n",
    "vc.release()\n",
    "cv2.destroyWindow(\"preview\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "vc.release()\n",
    "cv2.destroyWindow(\"preview\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.12 ('env_pytorch')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "feb008462c7d0aa707740c104e0790392f3f73e4fe42a3bbb6500681b1268c10"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
